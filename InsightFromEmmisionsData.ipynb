{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import Concentration data from dataframes\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_csvs_to_dfs(directory):\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "    data_frames = {}\n",
    "    for file in csv_files:\n",
    "        df_name = file[:-4]  # Removing the '.csv' part to use as the dictionary key\n",
    "        path = os.path.join(directory, file)\n",
    "        data_frames[df_name] = pd.read_csv(path)\n",
    "    return data_frames\n",
    "\n",
    "#point to the CSV files that are located in a folder named 'data_folder' in the current directory\n",
    "directory_path = 'C://Users//tayla//Documents//Emmisions_Data//'\n",
    "data_frames_dict = load_csvs_to_dfs(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame PostLAEI2013_2013_NO2:\n",
      "        x       y     conct  year Pollutant\n",
      "0  501460  170580  31.31919  2013       NO2\n",
      "1  501460  170600  31.55455  2013       NO2\n",
      "2  501460  170620  31.79392  2013       NO2\n",
      "3  501460  170640  32.03141  2013       NO2\n",
      "4  501460  170660  32.26324  2013       NO2\n",
      "Updated DataFrame PostLAEI2013_2013_NOx:\n",
      "        x       y     conct  year Pollutant\n",
      "0  501460  170580  49.21837  2013       NOx\n",
      "1  501460  170600  49.78666  2013       NOx\n",
      "2  501460  170620  50.36728  2013       NOx\n",
      "3  501460  170640  50.94635  2013       NOx\n",
      "4  501460  170660  51.51179  2013       NOx\n",
      "Updated DataFrame PostLAEI2013_2013_PM10:\n",
      "        x       y     conct  year Pollutant\n",
      "0  501460  170580  23.74403  2013      PM10\n",
      "1  501460  170600  23.78645  2013      PM10\n",
      "2  501460  170620  23.82961  2013      PM10\n",
      "3  501460  170640  23.87249  2013      PM10\n",
      "4  501460  170660  23.91457  2013      PM10\n",
      "Updated DataFrame PostLAEI2013_2013_PM10d:\n",
      "        x       y     conct  year Pollutant\n",
      "0  501460  170580  9.302350  2013     PM10d\n",
      "1  501460  170600  9.387261  2013     PM10d\n",
      "2  501460  170620  9.473991  2013     PM10d\n",
      "3  501460  170640  9.560539  2013     PM10d\n",
      "4  501460  170660  9.645805  2013     PM10d\n",
      "Updated DataFrame PostLAEI2013_2013_PM25:\n",
      "        x       y     conct  year Pollutant\n",
      "0  501460  170580  14.90253  2013      PM25\n",
      "1  501460  170600  14.91900  2013      PM25\n",
      "2  501460  170620  14.93577  2013      PM25\n",
      "3  501460  170640  14.95249  2013      PM25\n",
      "4  501460  170660  14.96894  2013      PM25\n",
      "Combined DataFrame Preview:\n",
      "        x       y     conct  year Pollutant\n",
      "0  501460  170580  31.31919  2013       NO2\n",
      "1  501460  170600  31.55455  2013       NO2\n",
      "2  501460  170620  31.79392  2013       NO2\n",
      "3  501460  170640  32.03141  2013       NO2\n",
      "4  501460  170660  32.26324  2013       NO2\n"
     ]
    }
   ],
   "source": [
    "# Updating DataFrames and storing them separately\n",
    "all_data_frames = []  # List to hold all data frames for later concatenation\n",
    "for df_name, df in data_frames_dict.items():\n",
    "    # Extract the pollutant type from the DataFrame name\n",
    "    pollutant = df_name.split('_')[2]\n",
    "    df['Pollutant'] = pollutant\n",
    "    all_data_frames.append(df.copy())  # Append a copy of the updated DataFrame to the list\n",
    "    data_frames_dict[df_name] = df  # Update the dictionary with the modified DataFrame\n",
    "    print(f\"Updated DataFrame {df_name}:\")\n",
    "    print(df.head())  # Print the first few rows of each updated DataFrame\n",
    "\n",
    "# Concatenate all updated DataFrames into one\n",
    "combined_df_vertical = pd.concat(all_data_frames, ignore_index=True)\n",
    "\n",
    "# Print the head of the combined DataFrame to verify\n",
    "print(\"Combined DataFrame Preview:\")\n",
    "print(combined_df_vertical.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available DataFrames: ['PostLAEI2013_2013_NO2', 'PostLAEI2013_2013_NOx', 'PostLAEI2013_2013_PM10', 'PostLAEI2013_2013_PM10d', 'PostLAEI2013_2013_PM25']\n"
     ]
    }
   ],
   "source": [
    "available_dfs = list(data_frames_dict.keys())\n",
    "print(\"Available DataFrames:\", available_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 8.896579374803949\n"
     ]
    }
   ],
   "source": [
    "#example knn ml model on No2 data\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# demonstrate on dataframe\n",
    "df = data_frames_dict['PostLAEI2013_2013_NO2']  # Use the appropriate key for your DataFrame\n",
    "\n",
    "# Prepare the feature matrix and target vector\n",
    "X = df[['x', 'y']]  # Features are the coordinates\n",
    "y = df['conct']     # Target is the concentration\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating and training the KNN regressor\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5) \n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the model (u\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plotting 3d plots for data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Function to plot each DataFrame\n",
    "def plot_3d_scatter(df, title):\n",
    "    fig = plt.figure(figsize=(10, 8))  # Set the figure size\n",
    "    ax = fig.add_subplot(111, projection='3d')  # Create a 3D subplot\n",
    "\n",
    "    # Scatter plot using x, y, and conct columns\n",
    "    scatter = ax.scatter(df['x'], df['y'], df['conct'], c=df['conct'], cmap='viridis', alpha=0.6)\n",
    "\n",
    "    # Labeling\n",
    "    ax.set_xlabel('X Coordinate')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "    ax.set_zlabel('Concentration')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Color bar to show concentration levels\n",
    "    cbar = fig.colorbar(scatter, pad=0.1)\n",
    "    cbar.set_label('Concentration')\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "# Iterate over each DataFrame and create a plot\n",
    "for name, df in data_frames_dict.items():\n",
    "    plot_3d_scatter(df, f\"3D Scatter Plot of {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
